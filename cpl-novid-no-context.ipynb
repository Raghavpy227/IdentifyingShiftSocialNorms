{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install openprompt\n\nimport pandas as pd\nfrom openprompt.data_utils import InputExample\nimport torch\nimport os\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import balanced_accuracy_score,f1_score,classification_report\nfrom sklearn.model_selection import train_test_split\nfrom openprompt.config import get_config, save_config_to_yaml\nfrom yacs.config import CfgNode\nfrom tqdm.contrib import tenumerate","metadata":{"execution":{"iopub.status.busy":"2023-08-11T21:49:17.640725Z","iopub.execute_input":"2023-08-11T21:49:17.641093Z","iopub.status.idle":"2023-08-11T21:49:47.502012Z","shell.execute_reply.started":"2023-08-11T21:49:17.641060Z","shell.execute_reply":"2023-08-11T21:49:47.500617Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting openprompt\n  Downloading openprompt-1.0.1-py3-none-any.whl (146 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.4/146.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: transformers>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from openprompt) (4.30.2)\nCollecting sentencepiece==0.1.96 (from openprompt)\n  Downloading sentencepiece-0.1.96-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.62.2 in /opt/conda/lib/python3.10/site-packages (from openprompt) (4.65.0)\nRequirement already satisfied: tensorboardX in /opt/conda/lib/python3.10/site-packages (from openprompt) (2.6)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from openprompt) (3.2.4)\nCollecting yacs (from openprompt)\n  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from openprompt) (0.3.6)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from openprompt) (2.1.0)\nCollecting rouge==1.0.0 (from openprompt)\n  Downloading rouge-1.0.0-py3-none-any.whl (14 kB)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from openprompt) (11.0.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from openprompt) (1.11.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge==1.0.0->openprompt) (1.16.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (0.3.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->openprompt) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->openprompt) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->openprompt) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets->openprompt) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->openprompt) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->openprompt) (0.18.0)\nRequirement already satisfied: protobuf<4,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorboardX->openprompt) (3.20.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (1.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.10.0->openprompt) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.10.0->openprompt) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.10.0->openprompt) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.10.0->openprompt) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.10.0->openprompt) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->openprompt) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->openprompt) (2023.3)\nInstalling collected packages: sentencepiece, yacs, rouge, openprompt\n  Attempting uninstall: sentencepiece\n    Found existing installation: sentencepiece 0.1.99\n    Uninstalling sentencepiece-0.1.99:\n      Successfully uninstalled sentencepiece-0.1.99\nSuccessfully installed openprompt-1.0.1 rouge-1.0.0 sentencepiece-0.1.96 yacs-0.1.8\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"path=r\"/kaggle/input/rs-2012-03\"\ndf=pd.read_csv(os.path.join(path,\"RS_2012-03_violations2.csv\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T21:49:47.507146Z","iopub.execute_input":"2023-08-11T21:49:47.508194Z","iopub.status.idle":"2023-08-11T21:49:53.884516Z","shell.execute_reply.started":"2023-08-11T21:49:47.508153Z","shell.execute_reply":"2023-08-11T21:49:53.883416Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"classes = [ # There are two classes in Sentiment Analysis, one for negative and one for positive\n    \"racial_slur\",\n    \"self_harm\",\n    \"Homophobia\",\n    \"Incivility\",\n    \"harrassment\",\n    \"No Violations\"\n]\n\nencoder = LabelEncoder()\ndf[\"label\"]=encoder.fit_transform(df[\"violation\"])\n\nle_name_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n\nprint(le_name_mapping)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-11T21:49:53.886110Z","iopub.execute_input":"2023-08-11T21:49:53.886634Z","iopub.status.idle":"2023-08-11T21:49:53.920200Z","shell.execute_reply.started":"2023-08-11T21:49:53.886590Z","shell.execute_reply":"2023-08-11T21:49:53.919100Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"{'Homophobia': 0, 'Incivility': 1, 'No Violations': 2, 'harrassment': 3, 'racial_slur': 4, 'self_harm': 5}\n","output_type":"stream"}]},{"cell_type":"code","source":"from openprompt.plms import load_plm\nfrom openprompt.lm_bff_trainer import LMBFFClassificationRunner,ClassificationRunner\nplm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2023-08-11T21:49:53.923177Z","iopub.execute_input":"2023-08-11T21:49:53.923865Z","iopub.status.idle":"2023-08-11T21:49:58.400677Z","shell.execute_reply.started":"2023-08-11T21:49:53.923827Z","shell.execute_reply":"2023-08-11T21:49:58.399617Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ebe0770e9cc48b389cb83e3f2b05b84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e5f3e94c1f14cb5a17a90be7867d1ba"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcb7aad14c3e461b9fb1bf761ec69fc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02352ff1c457459fb8884cbd01f9bff8"}},"metadata":{}}]},{"cell_type":"code","source":"from openprompt.prompts import ManualTemplate\n\npromptTemplate = ManualTemplate(\n    text = '{\"placeholder\":\"text_b\"}, Which violation is it? {\"mask\"} ',\n    tokenizer = tokenizer,\n)\n\nbad_words = {\n    \"racial_slur\": [\"nigga\",\"nigger\",\"uncle tom\",\"negro\",\"niggerhead\",\"house slave\",\"monkeyboy\"],\n    \"self_harm\": [\"kill yourself\", \"commit suicide\"],\n    \"Homophobia\":[\"lesbo\",\"faggot\",\"fag\",'cocksucker'],\n    \"Incivility\":[\"dickhead\",\"twat\",\"cunt\",\"whore\",\"retard\",\"bitch\",\"asshole\",\"dimwit\",\"bullshit\",\"fuck u\",\"fuck you\",\"motherfuck\"],\n    \"harrassment\":[\"penis\",\"pussy\",\"dick\",\"tits\",\"moron\",\"suck dick\",\"sexy bitch\"]\n}","metadata":{"execution":{"iopub.status.busy":"2023-08-11T21:49:58.402464Z","iopub.execute_input":"2023-08-11T21:49:58.402862Z","iopub.status.idle":"2023-08-11T21:49:58.410357Z","shell.execute_reply.started":"2023-08-11T21:49:58.402825Z","shell.execute_reply":"2023-08-11T21:49:58.409202Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"bad_set=set()\nfor k,v in bad_words.items():\n    for i in bad_words[k]: \n        bad_set.add(i)\nall_set=set()\nfor i in df[\"context\"]:\n   for k in i.split(' '):\n       all_set.add(k.lower())\n    \nno_vio = all_set.difference(bad_set)  \nno_vio=list(no_vio)\nno_vio=no_vio[0:len(no_vio):5000]\n\n    \n \nfrom openprompt.prompts import ManualVerbalizer\npromptVerbalizer = ManualVerbalizer(\n    classes = classes,\n    label_words = {\n        \"racial_slur\": [\"nigga\",\"nigger\",\"uncle tom\",\"negro\",\"niggerhead\",\"house slave\",\"monkeyboy\"],\n        \"self_harm\": [\"kill yourself\", \"commit suicide\"],\n        \"Homophobia\":[\"lesbo\",\"faggot\",\"fag\",'cocksucker'],\n        \"Incivility\":[\"dickhead\",\"twat\",\"cunt\",\"whore\",\"retard\",\"bitch\",\"asshole\",\"dimwit\",\"bullshit\",\"fuck u\",\"fuck you\",\"motherfuck\"],\n        \"harrassment\":[\"penis\",\"pussy\",\"dick\",\"tits\",\"moron\",\"suck dick\",\"sexy bitch\"],\n        \"No Violations\": no_vio\n    },\n    tokenizer = tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T21:49:58.412949Z","iopub.execute_input":"2023-08-11T21:49:58.413715Z","iopub.status.idle":"2023-08-11T21:50:17.932000Z","shell.execute_reply.started":"2023-08-11T21:49:58.413678Z","shell.execute_reply":"2023-08-11T21:50:17.930708Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from openprompt import PromptForClassification\npromptModel = PromptForClassification(\n    template = promptTemplate,\n    plm = plm,\n    verbalizer = promptVerbalizer,\n    freeze_plm=False,\n    plm_eval_mode=False\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-11T21:50:17.937196Z","iopub.execute_input":"2023-08-11T21:50:17.939722Z","iopub.status.idle":"2023-08-11T21:50:17.947508Z","shell.execute_reply.started":"2023-08-11T21:50:17.939683Z","shell.execute_reply":"2023-08-11T21:50:17.946498Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data_train , data_val = train_test_split(df,train_size=0.75,random_state=2018,stratify=df['label'])\n#data_train,data_val = train_test_split(data_train_val,train_size=0.25,random_state=2018,stratify=data_train_val['label'])\n\ndef InputExampleConverter(df): \n    dataset=[]\n    count=0\n    violation_sentence = df[\"sentence\"]\n    label=df[\"label\"]\n    context=df[\"context\"]\n    print(\"Creating Dataset\")     \n    for i in violation_sentence: \n        dataset.append(InputExample(guid=count,text_a=context[count],text_b=i,label=label[count]))\n        count=count+1\n    return(dataset)\ndata_train=InputExampleConverter(data_train.reset_index())\ndata_val=InputExampleConverter(data_val.reset_index())\n#data_test=InputExampleConverter(data_test.reset_index())    \n\n        \n\n\nfrom openprompt import PromptDataLoader\ndata_loader_train = PromptDataLoader(\n    dataset = data_train,\n    tokenizer = tokenizer,\n    template = promptTemplate,\n    tokenizer_wrapper_class=WrapperClass,\n    shuffle=True\n)\n\ndata_loader_val = PromptDataLoader(\n    dataset = data_val,\n    tokenizer = tokenizer,\n    template = promptTemplate,\n    tokenizer_wrapper_class=WrapperClass,\n    shuffle=True\n)\n'''\ndata_loader_test = PromptDataLoader(\n    dataset = data_test,\n    tokenizer = tokenizer,\n    template = promptTemplate,\n    tokenizer_wrapper_class=WrapperClass,\n    shuffle=True\n)\n'''","metadata":{"execution":{"iopub.status.busy":"2023-08-11T21:52:13.944005Z","iopub.execute_input":"2023-08-11T21:52:13.944572Z","iopub.status.idle":"2023-08-11T21:55:18.295248Z","shell.execute_reply.started":"2023-08-11T21:52:13.944525Z","shell.execute_reply":"2023-08-11T21:55:18.294213Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Creating Dataset\nCreating Dataset\n","output_type":"stream"},{"name":"stderr","text":"tokenizing: 28it [00:00, 265.86it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1626 > 512). Running this sequence through the model will result in indexing errors\ntokenizing: 45762it [02:16, 335.30it/s]\ntokenizing: 15254it [00:44, 339.70it/s]\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'\\ndata_loader_test = PromptDataLoader(\\n    dataset = data_test,\\n    tokenizer = tokenizer,\\n    template = promptTemplate,\\n    tokenizer_wrapper_class=WrapperClass,\\n    shuffle=True\\n)\\n'"},"metadata":{}}]},{"cell_type":"code","source":"predictions=[]\n\nuse_cuda = True\nif use_cuda:\n    promptModel=  promptModel.cuda()\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# Now the training is standard\nfrom transformers import  AdamW, get_linear_schedule_with_warmup\nloss_func = torch.nn.CrossEntropyLoss()\noptimizer = AdamW(promptModel.parameters(), lr=1e-5)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T21:55:18.297427Z","iopub.execute_input":"2023-08-11T21:55:18.297890Z","iopub.status.idle":"2023-08-11T21:55:23.789732Z","shell.execute_reply.started":"2023-08-11T21:55:18.297852Z","shell.execute_reply":"2023-08-11T21:55:23.788610Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfor epoch in range(5):\n    tot_loss = 0\n    prev_score=0\n    val_score=[]\n    test_score=[]\n    for step, inputs in tenumerate(data_loader_train):\n        if use_cuda:\n            inputs = inputs.to(device) \n        #print(step)   \n        logits = promptModel(inputs)\n        logits=logits.to(device)\n        labels = inputs['label']\n        labels=labels.to(device)\n        loss = loss_func(logits,labels.type(torch.LongTensor).to(device))\n        loss.backward()\n        tot_loss += loss.item()\n        optimizer.step()\n        optimizer.zero_grad()\n        if step %5000 ==1:\n            print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n            \n            try: \n                torch.save({\n\n            'epoch': epoch,\n\n            'model_state_dict': promptModel.state_dict(),\n\n            'optimizer_state_dict': optimizer.state_dict(),\n\n            'loss': loss,\n\n            },os.path.join(path,\"violation_type_model_chkpt.pt\"))\n                \n            except:\n                continue\n    allpreds = []\n    alllabels = []\n    print(\"getting val score after epoch \"+ str(epoch))\n    for step, inputs in tenumerate(data_loader_val):\n        if use_cuda:\n            inputs = inputs.cuda()\n        logits = promptModel(inputs)\n        labels = inputs['label']\n        alllabels.extend(labels.cpu().tolist())\n        allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n\n    print(f1_score(alllabels,allpreds,average=\"micro\" ))\n    print(classification_report(alllabels,allpreds))  \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-11T21:55:23.791448Z","iopub.execute_input":"2023-08-11T21:55:23.792380Z","iopub.status.idle":"2023-08-12T08:20:59.319151Z","shell.execute_reply.started":"2023-08-11T21:55:23.792338Z","shell.execute_reply":"2023-08-12T08:20:59.317974Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45762 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"684503e56ca74b91ab252dd621473c98"}},"metadata":{}},{"name":"stdout","text":"Epoch 0, average loss: 3.2978603839874268\nEpoch 0, average loss: 0.42030673310039984\nEpoch 0, average loss: 0.3243988596719969\nEpoch 0, average loss: 0.2903059456407207\nEpoch 0, average loss: 0.2650684100013636\nEpoch 0, average loss: 0.2492117375109385\nEpoch 0, average loss: 0.23413849382015697\nEpoch 0, average loss: 0.22437012842782814\nEpoch 0, average loss: 0.21666976985066996\nEpoch 0, average loss: 0.20970070878347657\ngetting val score after epoch 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"374daa3a3e2f43af9813147422e393ff"}},"metadata":{}},{"name":"stdout","text":"0.9542415104234955\n              precision    recall  f1-score   support\n\n           0       0.93      0.74      0.82       280\n           1       0.94      0.95      0.94      4311\n           2       0.99      0.96      0.97      8460\n           3       0.89      0.97      0.93      1954\n           4       0.85      0.93      0.89       194\n           5       0.88      0.84      0.86        55\n\n    accuracy                           0.95     15254\n   macro avg       0.91      0.90      0.90     15254\nweighted avg       0.96      0.95      0.95     15254\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45762 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3346bb7783114369a25f639644a66790"}},"metadata":{}},{"name":"stdout","text":"Epoch 1, average loss: 0.016240623026533285\nEpoch 1, average loss: 0.13771770515250326\nEpoch 1, average loss: 0.14081600602793065\nEpoch 1, average loss: 0.14196282589827364\nEpoch 1, average loss: 0.1428730156669704\nEpoch 1, average loss: 0.14253335637194758\nEpoch 1, average loss: 0.14213410061741247\nEpoch 1, average loss: 0.14205353173950583\nEpoch 1, average loss: 0.14239671157204314\nEpoch 1, average loss: 0.14055676253310437\ngetting val score after epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2abf3f2588d4f40ae2feeb5fc18eff7"}},"metadata":{}},{"name":"stdout","text":"0.9515536908351908\n              precision    recall  f1-score   support\n\n           0       0.92      0.79      0.85       280\n           1       0.88      0.99      0.94      4311\n           2       1.00      0.95      0.97      8460\n           3       0.94      0.89      0.91      1954\n           4       0.97      0.78      0.87       194\n           5       0.90      0.85      0.88        55\n\n    accuracy                           0.95     15254\n   macro avg       0.94      0.88      0.90     15254\nweighted avg       0.95      0.95      0.95     15254\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45762 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f4691b741da497d907126364d294935"}},"metadata":{}},{"name":"stdout","text":"Epoch 2, average loss: 2.944425978057552e-05\nEpoch 2, average loss: 0.12135060028320657\nEpoch 2, average loss: 0.12093624708392875\nEpoch 2, average loss: 0.12237728026106212\nEpoch 2, average loss: 0.12419985974543747\nEpoch 2, average loss: 0.12888136031196817\nEpoch 2, average loss: 0.1285533197269052\nEpoch 2, average loss: 0.129222573546129\nEpoch 2, average loss: 0.128093349294835\nEpoch 2, average loss: 0.13171691340146163\ngetting val score after epoch 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22c7a6d6c7174916bc943422bf9f05aa"}},"metadata":{}},{"name":"stdout","text":"0.9572571128884227\n              precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87       280\n           1       0.94      0.94      0.94      4311\n           2       0.99      0.96      0.98      8460\n           3       0.88      0.98      0.93      1954\n           4       0.85      0.93      0.89       194\n           5       0.88      0.84      0.86        55\n\n    accuracy                           0.96     15254\n   macro avg       0.90      0.92      0.91     15254\nweighted avg       0.96      0.96      0.96     15254\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45762 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da66344b230848cb8a6e9e6c491f48c9"}},"metadata":{}},{"name":"stdout","text":"Epoch 3, average loss: 1.3282057829201221\nEpoch 3, average loss: 0.12297257945470444\nEpoch 3, average loss: 0.12820211762927322\nEpoch 3, average loss: 0.13747263243683894\nEpoch 3, average loss: 0.13468239378313235\nEpoch 3, average loss: 0.13000098551664976\nEpoch 3, average loss: 0.12974631018849597\nEpoch 3, average loss: 0.12971122252388576\nEpoch 3, average loss: 0.130269395405788\nEpoch 3, average loss: 0.13089819007075312\ngetting val score after epoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b3a31639e7344a08453222611e0b8e0"}},"metadata":{}},{"name":"stdout","text":"0.9566671037105021\n              precision    recall  f1-score   support\n\n           0       0.78      0.97      0.87       280\n           1       0.94      0.94      0.94      4311\n           2       0.99      0.96      0.98      8460\n           3       0.89      0.98      0.93      1954\n           4       0.87      0.90      0.88       194\n           5       0.96      0.80      0.87        55\n\n    accuracy                           0.96     15254\n   macro avg       0.90      0.93      0.91     15254\nweighted avg       0.96      0.96      0.96     15254\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45762 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6acd0626d714f8580b099047920f58e"}},"metadata":{}},{"name":"stdout","text":"Epoch 4, average loss: 1.0430757811263902e-05\nEpoch 4, average loss: 0.11976519109586889\nEpoch 4, average loss: 0.1214190014570449\nEpoch 4, average loss: 0.11832309702974035\nEpoch 4, average loss: 0.12262858790390094\nEpoch 4, average loss: 0.12397536589811843\nEpoch 4, average loss: 0.123409029012607\nEpoch 4, average loss: 0.12313569956512063\nEpoch 4, average loss: 0.12165101173647781\nEpoch 4, average loss: 0.12322537172044574\ngetting val score after epoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd4825b8af2740d7948aaa4c12acfac4"}},"metadata":{}},{"name":"stdout","text":"0.9520781434377869\n              precision    recall  f1-score   support\n\n           0       0.81      0.93      0.86       280\n           1       0.89      0.98      0.94      4311\n           2       0.99      0.96      0.97      8460\n           3       0.95      0.89      0.92      1954\n           4       0.92      0.81      0.86       194\n           5       0.94      0.84      0.88        55\n\n    accuracy                           0.95     15254\n   macro avg       0.92      0.90      0.91     15254\nweighted avg       0.95      0.95      0.95     15254\n\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(promptModel,os.path.join(path,\"violation_detector.pt\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T21:50:20.522844Z","iopub.status.idle":"2023-08-11T21:50:20.523340Z","shell.execute_reply.started":"2023-08-11T21:50:20.523084Z","shell.execute_reply":"2023-08-11T21:50:20.523107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}