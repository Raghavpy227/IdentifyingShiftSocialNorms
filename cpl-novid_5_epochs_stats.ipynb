{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install openprompt\n\nimport pandas as pd\nfrom openprompt.data_utils import InputExample\nimport torch\nimport os\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import balanced_accuracy_score,f1_score,classification_report\nfrom sklearn.model_selection import train_test_split\nfrom openprompt.config import get_config, save_config_to_yaml\nfrom yacs.config import CfgNode\nfrom tqdm.contrib import tenumerate","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:16:27.341196Z","iopub.execute_input":"2023-08-12T13:16:27.341543Z","iopub.status.idle":"2023-08-12T13:16:54.230850Z","shell.execute_reply.started":"2023-08-12T13:16:27.341514Z","shell.execute_reply":"2023-08-12T13:16:54.229866Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting openprompt\n  Downloading openprompt-1.0.1-py3-none-any.whl (146 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.4/146.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: transformers>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from openprompt) (4.30.2)\nCollecting sentencepiece==0.1.96 (from openprompt)\n  Downloading sentencepiece-0.1.96-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.62.2 in /opt/conda/lib/python3.10/site-packages (from openprompt) (4.65.0)\nRequirement already satisfied: tensorboardX in /opt/conda/lib/python3.10/site-packages (from openprompt) (2.6)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from openprompt) (3.2.4)\nCollecting yacs (from openprompt)\n  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from openprompt) (0.3.6)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from openprompt) (2.1.0)\nCollecting rouge==1.0.0 (from openprompt)\n  Downloading rouge-1.0.0-py3-none-any.whl (14 kB)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from openprompt) (11.0.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from openprompt) (1.11.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge==1.0.0->openprompt) (1.16.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.10.0->openprompt) (0.3.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->openprompt) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->openprompt) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->openprompt) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets->openprompt) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->openprompt) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->openprompt) (0.18.0)\nRequirement already satisfied: protobuf<4,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorboardX->openprompt) (3.20.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->openprompt) (1.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.10.0->openprompt) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.10.0->openprompt) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.10.0->openprompt) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.10.0->openprompt) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.10.0->openprompt) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->openprompt) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->openprompt) (2023.3)\nInstalling collected packages: sentencepiece, yacs, rouge, openprompt\n  Attempting uninstall: sentencepiece\n    Found existing installation: sentencepiece 0.1.99\n    Uninstalling sentencepiece-0.1.99:\n      Successfully uninstalled sentencepiece-0.1.99\nSuccessfully installed openprompt-1.0.1 rouge-1.0.0 sentencepiece-0.1.96 yacs-0.1.8\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"path=r\"/kaggle/input/rs-2012-03\"\ndf=pd.read_csv(os.path.join(path,\"RS_2012-03_violations2.csv\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:16:54.232767Z","iopub.execute_input":"2023-08-12T13:16:54.233114Z","iopub.status.idle":"2023-08-12T13:17:00.364543Z","shell.execute_reply.started":"2023-08-12T13:16:54.233087Z","shell.execute_reply":"2023-08-12T13:17:00.363489Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"classes = [ # There are two classes in Sentiment Analysis, one for negative and one for positive\n    \"racial_slur\",\n    \"self_harm\",\n    \"Homophobia\",\n    \"Incivility\",\n    \"harrassment\",\n    \"No Violations\"\n]\n\nencoder = LabelEncoder()\ndf[\"label\"]=encoder.fit_transform(df[\"violation\"])\n\nle_name_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n\nprint(le_name_mapping)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:17:00.366236Z","iopub.execute_input":"2023-08-12T13:17:00.366980Z","iopub.status.idle":"2023-08-12T13:17:00.394685Z","shell.execute_reply.started":"2023-08-12T13:17:00.366942Z","shell.execute_reply":"2023-08-12T13:17:00.393319Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"{'Homophobia': 0, 'Incivility': 1, 'No Violations': 2, 'harrassment': 3, 'racial_slur': 4, 'self_harm': 5}\n","output_type":"stream"}]},{"cell_type":"code","source":"from openprompt.plms import load_plm\nfrom openprompt.lm_bff_trainer import LMBFFClassificationRunner,ClassificationRunner\nplm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:17:00.398049Z","iopub.execute_input":"2023-08-12T13:17:00.398349Z","iopub.status.idle":"2023-08-12T13:17:09.617251Z","shell.execute_reply.started":"2023-08-12T13:17:00.398324Z","shell.execute_reply":"2023-08-12T13:17:09.616245Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f3dd34801784660bf5e028168ea3799"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6b4e900bd26450a823a16a5c408cbcd"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6c73a63e8e746cc94962bd5e64d3b5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae6b642d0ed4418a9deb798579e61da2"}},"metadata":{}}]},{"cell_type":"code","source":"from openprompt.prompts import ManualTemplate\n\npromptTemplate = ManualTemplate(\n    text = '{\"placeholder\":\"text_a\"} was the context for {\"placeholder\":\"text_b\"}, Which violation is it? {\"mask\"}' ,\n    tokenizer = tokenizer,\n)\n\nbad_words = {\n    \"racial_slur\": [\"nigga\",\"nigger\",\"uncle tom\",\"negro\",\"niggerhead\",\"house slave\",\"monkeyboy\"],\n    \"self_harm\": [\"kill yourself\", \"commit suicide\"],\n    \"Homophobia\":[\"lesbo\",\"faggot\",\"fag\",'cocksucker'],\n    \"Incivility\":[\"dickhead\",\"twat\",\"cunt\",\"whore\",\"retard\",\"bitch\",\"asshole\",\"dimwit\",\"bullshit\",\"fuck u\",\"fuck you\",\"motherfuck\"],\n    \"harrassment\":[\"penis\",\"pussy\",\"dick\",\"tits\",\"moron\",\"suck dick\",\"sexy bitch\"]\n}","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:17:09.618641Z","iopub.execute_input":"2023-08-12T13:17:09.619092Z","iopub.status.idle":"2023-08-12T13:17:09.626259Z","shell.execute_reply.started":"2023-08-12T13:17:09.619056Z","shell.execute_reply":"2023-08-12T13:17:09.625089Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"bad_set=set()\nfor k,v in bad_words.items():\n    for i in bad_words[k]: \n        bad_set.add(i)\nall_set=set()\nfor i in df[\"context\"]:\n   for k in i.split(' '):\n       all_set.add(k.lower())\n    \nno_vio = all_set.difference(bad_set)  \nno_vio=list(no_vio)\nno_vio=no_vio[0:len(no_vio):5000]\n\n    \n \nfrom openprompt.prompts import ManualVerbalizer\npromptVerbalizer = ManualVerbalizer(\n    classes = classes,\n    label_words = {\n        \"racial_slur\": [\"nigga\",\"nigger\",\"uncle tom\",\"negro\",\"niggerhead\",\"house slave\",\"monkeyboy\"],\n        \"self_harm\": [\"kill yourself\", \"commit suicide\"],\n        \"Homophobia\":[\"lesbo\",\"faggot\",\"fag\",'cocksucker'],\n        \"Incivility\":[\"dickhead\",\"twat\",\"cunt\",\"whore\",\"retard\",\"bitch\",\"asshole\",\"dimwit\",\"bullshit\",\"fuck u\",\"fuck you\",\"motherfuck\"],\n        \"harrassment\":[\"penis\",\"pussy\",\"dick\",\"tits\",\"moron\",\"suck dick\",\"sexy bitch\"],\n        \"No Violations\": no_vio\n    },\n    tokenizer = tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:17:09.627774Z","iopub.execute_input":"2023-08-12T13:17:09.628131Z","iopub.status.idle":"2023-08-12T13:17:27.294278Z","shell.execute_reply.started":"2023-08-12T13:17:09.628097Z","shell.execute_reply":"2023-08-12T13:17:27.293297Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from openprompt import PromptForClassification\npromptModel = PromptForClassification(\n    template = promptTemplate,\n    plm = plm,\n    verbalizer = promptVerbalizer,\n    freeze_plm=False,\n    plm_eval_mode=False\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:17:27.297677Z","iopub.execute_input":"2023-08-12T13:17:27.297973Z","iopub.status.idle":"2023-08-12T13:17:27.302983Z","shell.execute_reply.started":"2023-08-12T13:17:27.297947Z","shell.execute_reply":"2023-08-12T13:17:27.301899Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data_train , data_val = train_test_split(df,train_size=0.75,random_state=2018,stratify=df['label'])\n#data_train,data_val = train_test_split(data_train_val,train_size=0.25,random_state=2018,stratify=data_train_val['label'])\n\ndef InputExampleConverter(df): \n    dataset=[]\n    count=0\n    violation_sentence = df[\"sentence\"]\n    label=df[\"label\"]\n    context=df[\"context\"]\n    print(\"Creating Dataset\")     \n    for i in violation_sentence: \n        dataset.append(InputExample(guid=count,text_a=context[count],text_b=i,label=label[count]))\n        count=count+1\n    return(dataset)\ndata_train=InputExampleConverter(data_train.reset_index())\ndata_val=InputExampleConverter(data_val.reset_index())\n#data_test=InputExampleConverter(data_test.reset_index())    \n\n        \n\n\nfrom openprompt import PromptDataLoader\ndata_loader_train = PromptDataLoader(\n    dataset = data_train,\n    tokenizer = tokenizer,\n    template = promptTemplate,\n    tokenizer_wrapper_class=WrapperClass,\n    shuffle=True\n)\n\ndata_loader_val = PromptDataLoader(\n    dataset = data_val,\n    tokenizer = tokenizer,\n    template = promptTemplate,\n    tokenizer_wrapper_class=WrapperClass,\n    shuffle=True\n)\n'''\ndata_loader_test = PromptDataLoader(\n    dataset = data_test,\n    tokenizer = tokenizer,\n    template = promptTemplate,\n    tokenizer_wrapper_class=WrapperClass,\n    shuffle=True\n)\n'''","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:17:27.304200Z","iopub.execute_input":"2023-08-12T13:17:27.304744Z","iopub.status.idle":"2023-08-12T13:44:44.548118Z","shell.execute_reply.started":"2023-08-12T13:17:27.304708Z","shell.execute_reply":"2023-08-12T13:44:44.547101Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Creating Dataset\nCreating Dataset\n","output_type":"stream"},{"name":"stderr","text":"tokenizing: 0it [00:00, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1524 > 512). Running this sequence through the model will result in indexing errors\ntokenizing: 45762it [20:20, 37.50it/s]\ntokenizing: 15254it [06:53, 36.87it/s]\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'\\ndata_loader_test = PromptDataLoader(\\n    dataset = data_test,\\n    tokenizer = tokenizer,\\n    template = promptTemplate,\\n    tokenizer_wrapper_class=WrapperClass,\\n    shuffle=True\\n)\\n'"},"metadata":{}}]},{"cell_type":"code","source":"predictions=[]\n\nuse_cuda = True\nif use_cuda:\n    promptModel=  promptModel.cuda()\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# Now the training is standard\nfrom transformers import  AdamW, get_linear_schedule_with_warmup\nloss_func = torch.nn.CrossEntropyLoss()\noptimizer = AdamW(promptModel.parameters(), lr=1e-5)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:44:44.549792Z","iopub.execute_input":"2023-08-12T13:44:44.550443Z","iopub.status.idle":"2023-08-12T13:44:49.890393Z","shell.execute_reply.started":"2023-08-12T13:44:44.550403Z","shell.execute_reply":"2023-08-12T13:44:49.889394Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfor epoch in range(10):\n    tot_loss = 0\n    prev_score=0\n    val_score=[]\n    test_score=[]\n    for step, inputs in tenumerate(data_loader_train):\n        if use_cuda:\n            inputs = inputs.to(device) \n        #print(step)   \n        logits = promptModel(inputs)\n        logits=logits.to(device)\n        labels = inputs['label']\n        labels=labels.to(device)\n        loss = loss_func(logits,labels.type(torch.LongTensor).to(device))\n        loss.backward()\n        tot_loss += loss.item()\n        optimizer.step()\n        optimizer.zero_grad()\n        if step %5000 ==1:\n            print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n            \n            try: \n                torch.save({\n\n            'epoch': epoch,\n\n            'model_state_dict': promptModel.state_dict(),\n\n            'optimizer_state_dict': optimizer.state_dict(),\n\n            'loss': loss,\n\n            },os.path.join(path,\"violation_type_model_chkpt.pt\"))\n                \n            except:\n                continue\n    allpreds = []\n    alllabels = []\n    print(\"getting val score after epoch \"+ str(epoch))\n    for step, inputs in tenumerate(data_loader_val):\n        if use_cuda:\n            inputs = inputs.cuda()\n        logits = promptModel(inputs)\n        labels = inputs['label']\n        alllabels.extend(labels.cpu().tolist())\n        allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n\n    print(f1_score(alllabels,allpreds,average=\"micro\" ))\n    print(classification_report(alllabels,allpreds))  \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:44:49.893820Z","iopub.execute_input":"2023-08-12T13:44:49.894630Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45762 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89e5425ba31f422892a0415789acb43d"}},"metadata":{}},{"name":"stdout","text":"Epoch 0, average loss: 1.7903161644935608\nEpoch 0, average loss: 1.0216323076659384\nEpoch 0, average loss: 0.9638755424967996\nEpoch 0, average loss: 0.9330157394077179\nEpoch 0, average loss: 0.9132328703087899\nEpoch 0, average loss: 0.8974678920088283\nEpoch 0, average loss: 0.8870737991765966\nEpoch 0, average loss: 0.8765657370096896\nEpoch 0, average loss: 0.8680584327154751\nEpoch 0, average loss: 0.8632002104879795\ngetting val score after epoch 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84efc26ad1d34faaa69d089b4f3318b1"}},"metadata":{}},{"name":"stdout","text":"0.6718893405008523\n              precision    recall  f1-score   support\n\n           0       0.90      0.06      0.12       280\n           1       0.66      0.40      0.50      4311\n           2       0.67      0.92      0.78      8460\n           3       0.75      0.33      0.46      1954\n           4       0.70      0.20      0.31       194\n           5       1.00      0.09      0.17        55\n\n    accuracy                           0.67     15254\n   macro avg       0.78      0.34      0.39     15254\nweighted avg       0.68      0.67      0.64     15254\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45762 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf4c575340574f58bae6eb10f69c7f2b"}},"metadata":{}},{"name":"stdout","text":"Epoch 1, average loss: 1.2084500044584274\nEpoch 1, average loss: 0.7613171779529537\nEpoch 1, average loss: 0.7601164546407234\nEpoch 1, average loss: 0.7636510769035917\nEpoch 1, average loss: 0.7603399025875338\nEpoch 1, average loss: 0.7613533001920562\nEpoch 1, average loss: 0.7578633136672085\nEpoch 1, average loss: 0.7591949503936062\nEpoch 1, average loss: 0.7576505978676985\nEpoch 1, average loss: 0.7569191167031437\ngetting val score after epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c338bf77d984d85924b9781725b0302"}},"metadata":{}},{"name":"stdout","text":"0.6827061754293956\n              precision    recall  f1-score   support\n\n           0       0.62      0.20      0.31       280\n           1       0.64      0.44      0.52      4311\n           2       0.69      0.91      0.78      8460\n           3       0.76      0.35      0.48      1954\n           4       0.63      0.42      0.51       194\n           5       0.58      0.20      0.30        55\n\n    accuracy                           0.68     15254\n   macro avg       0.65      0.42      0.48     15254\nweighted avg       0.68      0.68      0.66     15254\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45762 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2b5be28fb5a4e89a6e9ad0d07b690fc"}},"metadata":{}},{"name":"stdout","text":"Epoch 2, average loss: 1.227900743484497\nEpoch 2, average loss: 0.6816311937038316\nEpoch 2, average loss: 0.6873500150315701\nEpoch 2, average loss: 0.6908541848129285\nEpoch 2, average loss: 0.6919454097704445\nEpoch 2, average loss: 0.6947334728952413\nEpoch 2, average loss: 0.6963515889047235\nEpoch 2, average loss: 0.6964983929655003\nEpoch 2, average loss: 0.6994442107791332\nEpoch 2, average loss: 0.7005307481744523\ngetting val score after epoch 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f683d315597347f2952e6184d27f6f45"}},"metadata":{}},{"name":"stdout","text":"0.6586469122853023\n              precision    recall  f1-score   support\n\n           0       0.55      0.15      0.23       280\n           1       0.50      0.71      0.59      4311\n           2       0.78      0.72      0.75      8460\n           3       0.69      0.40      0.51      1954\n           4       0.64      0.39      0.48       194\n           5       0.79      0.20      0.32        55\n\n    accuracy                           0.66     15254\n   macro avg       0.66      0.43      0.48     15254\nweighted avg       0.69      0.66      0.66     15254\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45762 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d92c99973771498b87592ef591ca988d"}},"metadata":{}},{"name":"stdout","text":"Epoch 3, average loss: 0.5628748685121536\nEpoch 3, average loss: 0.6086154653594893\nEpoch 3, average loss: 0.6053036505293872\nEpoch 3, average loss: 0.6111145464936185\nEpoch 3, average loss: 0.6212403178671894\nEpoch 3, average loss: 0.6315835355030384\nEpoch 3, average loss: 0.633637711520294\nEpoch 3, average loss: 0.6364836736762705\nEpoch 3, average loss: 0.6416106392479234\nEpoch 3, average loss: 0.6443869391474415\ngetting val score after epoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da227ef49875424f9ba28b8dadae7f01"}},"metadata":{}},{"name":"stdout","text":"0.6704470958437131\n              precision    recall  f1-score   support\n\n           0       0.40      0.16      0.23       280\n           1       0.56      0.54      0.55      4311\n           2       0.74      0.81      0.77      8460\n           3       0.60      0.47      0.52      1954\n           4       0.60      0.44      0.51       194\n           5       0.45      0.42      0.43        55\n\n    accuracy                           0.67     15254\n   macro avg       0.56      0.47      0.50     15254\nweighted avg       0.66      0.67      0.66     15254\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45762 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211d988e517840b48b01847a1b6349bc"}},"metadata":{}},{"name":"stdout","text":"Epoch 4, average loss: 0.21609160769730806\nEpoch 4, average loss: 0.548054077679892\nEpoch 4, average loss: 0.5570701424328306\nEpoch 4, average loss: 0.5617562084108233\nEpoch 4, average loss: 0.5658810649400099\nEpoch 4, average loss: 0.5719224848727174\nEpoch 4, average loss: 0.5778062422483389\nEpoch 4, average loss: 0.5835437734987541\nEpoch 4, average loss: 0.5887875171603607\nEpoch 4, average loss: 0.5929448742053641\ngetting val score after epoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9099000274bb46f380b4dbca5ebbdea9"}},"metadata":{}},{"name":"stdout","text":"0.6714960010489052\n              precision    recall  f1-score   support\n\n           0       0.85      0.16      0.27       280\n           1       0.54      0.59      0.57      4311\n           2       0.74      0.80      0.77      8460\n           3       0.66      0.41      0.51      1954\n           4       0.47      0.41      0.44       194\n           5       0.68      0.24      0.35        55\n\n    accuracy                           0.67     15254\n   macro avg       0.66      0.43      0.48     15254\nweighted avg       0.67      0.67      0.66     15254\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45762 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"654098a5e1b04212bdd51e81ee02ea9a"}},"metadata":{}},{"name":"stdout","text":"Epoch 5, average loss: 0.2584132557094563\nEpoch 5, average loss: 0.49438531662708\nEpoch 5, average loss: 0.5055921148100418\nEpoch 5, average loss: 0.511271701747852\nEpoch 5, average loss: 0.5203532196134836\nEpoch 5, average loss: 0.5294188705465258\nEpoch 5, average loss: 0.5338809722918668\nEpoch 5, average loss: 0.538984329722015\nEpoch 5, average loss: 0.5438432304694156\nEpoch 5, average loss: 0.5508875655775383\ngetting val score after epoch 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5850f5e369b40cfb0a745d529e881ab"}},"metadata":{}},{"name":"stdout","text":"0.6731349154320179\n              precision    recall  f1-score   support\n\n           0       0.64      0.20      0.31       280\n           1       0.60      0.48      0.53      4311\n           2       0.73      0.84      0.78      8460\n           3       0.55      0.48      0.51      1954\n           4       0.53      0.43      0.47       194\n           5       0.41      0.31      0.35        55\n\n    accuracy                           0.67     15254\n   macro avg       0.58      0.46      0.49     15254\nweighted avg       0.66      0.67      0.66     15254\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45762 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c2c6c8ae8bf453881e50c382c065a6c"}},"metadata":{}},{"name":"stdout","text":"Epoch 6, average loss: 0.7851646244525909\nEpoch 6, average loss: 0.46561491552532924\nEpoch 6, average loss: 0.4732228925932715\nEpoch 6, average loss: 0.4820455273505272\nEpoch 6, average loss: 0.4861551356448\nEpoch 6, average loss: 0.49380886002308355\nEpoch 6, average loss: 0.5011107444223148\nEpoch 6, average loss: 0.5092869174591674\nEpoch 6, average loss: 0.5126835792966533\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(promptModel,os.path.join(path,\"violation_detector.pt\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T21:50:20.522844Z","iopub.status.idle":"2023-08-11T21:50:20.523340Z","shell.execute_reply.started":"2023-08-11T21:50:20.523084Z","shell.execute_reply":"2023-08-11T21:50:20.523107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}